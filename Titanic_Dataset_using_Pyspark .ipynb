{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0e586021-c06c-43b8-aec8-69b2b0603fe9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "#libraries will be imported were ever required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0ff31bbb-7fe6-421f-83b0-43d4b1394c78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "90478bf9-f6a6-4602-b9b1-400960951c6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#To create a basic SparkSession, just use SparkSession.builder\n",
    "spark = SparkSession.builder.appName('Titanic Dataset').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5b38ddd0-7df6-45f5-85c9-45503d95af5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Data set link : https://www.kaggle.com/c/titanic/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "85b8456d-6ca8-423c-a4fe-bf901090c3b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Process Titanic dataset using PySpark - SparkSQL libraries to answer questions given below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7e5ddded-ef51-42a0-a0db-b12f2c228109",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#2.i Load the  dataset into a Spark-DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "638816f5-3980-4109-8839-d0e25aeea273",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=spark.read.csv('D://M. Tech in Data Science & Machine Learning//Big Data Analytics//Sem_Prep//Titanic_dataset//train.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "83601a68-d0a8-4145-925f-b35705747646",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)#to display the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d0b2419e-6d5e-480b-91b9-fc23fc700b98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name                                               |Sex   |Age |SibSp|Parch|Ticket          |Fare   |Cabin|Embarked|\n",
      "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|1          |0       |3     |Braund, Mr. Owen Harris                            |male  |22.0|1    |0    |A/5 21171       |7.25   |null |S       |\n",
      "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)|female|38.0|1    |0    |PC 17599        |71.2833|C85  |C       |\n",
      "|3          |1       |3     |Heikkinen, Miss. Laina                             |female|26.0|0    |0    |STON/O2. 3101282|7.925  |null |S       |\n",
      "|4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)       |female|35.0|1    |0    |113803          |53.1   |C123 |S       |\n",
      "|5          |0       |3     |Allen, Mr. William Henry                           |male  |35.0|0    |0    |373450          |8.05   |null |S       |\n",
      "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,False)#view few records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3d02094c-65b6-4f34-acbf-b133fc46508c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------+-----------------+----+----+-----------------+------------------+-------------------+------------------+----------------+-----+--------+\n",
      "|summary|PassengerId|          Survived|           Pclass|Name| Sex|              Age|             SibSp|              Parch|            Ticket|            Fare|Cabin|Embarked|\n",
      "+-------+-----------+------------------+-----------------+----+----+-----------------+------------------+-------------------+------------------+----------------+-----+--------+\n",
      "|  count|        891|               891|              891| 891| 891|              714|               891|                891|               891|             891|  204|     889|\n",
      "|   mean|      446.0|0.3838383838383838|2.308641975308642|null|null|29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738|32.2042079685746| null|    null|\n",
      "+-------+-----------+------------------+-----------------+----+----+-----------------+------------------+-------------------+------------------+----------------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show(2)#summary of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cfa3db6b-a304-4832-96fa-c6fcb178ebe2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|Survived|Pclass|\n",
      "+--------+------+\n",
      "|       0|     3|\n",
      "|       1|     1|\n",
      "|       1|     3|\n",
      "|       1|     1|\n",
      "|       0|     3|\n",
      "+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Survived','Pclass').show(5)#to view selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5d19528a-163a-47ef-868d-a6db3e772418",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()#columns and type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3d75031e-5004-4ddb-ad1e-04891ed67a26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#2.ii How many people travelled from Titanic (total count)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c01cd2df-919a-4c62-990b-5ec35e2195c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total passengers count: 891\n"
     ]
    }
   ],
   "source": [
    "print('Total passengers count:',df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT Name)|\n",
      "+--------------------+\n",
      "|                 891|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct(Name)) from train\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8cac90f3-0dc2-4827-a4bc-e3b0769c0826",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#2.iii What was the average ticket fare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8168777b-fb04-447f-95a7-9d5936351f86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+----------------+\n",
       "|       avg(Fare)|\n",
       "+----------------+\n",
       "|32.2042079685746|\n",
       "+----------------+\n",
       "\n",
       "Average ticket fare : None\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+----------------+\n|       avg(Fare)|\n+----------------+\n|32.2042079685746|\n+----------------+\n\nAverage ticket fare : None\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Reference :https://www.geeksforgeeks.org/find-minimum-maximum-and-average-value-of-pyspark-dataframe-column/\n",
    "print('Average ticket fare :',df.agg({'Fare': 'avg'}).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|       avg(Fare)|\n",
      "+----------------+\n",
      "|32.2042079685746|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select avg(Fare) from train').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e9b24155-de35-4a39-aadf-a9a97cd88463",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#2.iv  What was the average age of people travelled from titanic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ff0ffedf-2c6e-4f22-8e72-dc764e23b302",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------------+\n",
       "|         avg(Age)|\n",
       "+-----------------+\n",
       "|29.69911764705882|\n",
       "+-----------------+\n",
       "\n",
       "Average age of people travelled from titanic : None\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+-----------------+\n|         avg(Age)|\n+-----------------+\n|29.69911764705882|\n+-----------------+\n\nAverage age of people travelled from titanic : None\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Average age of people travelled from titanic :',df.agg({'Age': 'avg'}).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d3f277e6-479a-4488-b4c3-5a9cf96f84b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#2.v What was the ratio of Lower class - Males to Upper class Females?\n",
    "\n",
    "#1st = Upper\n",
    "#2nd = Middle\n",
    "#3rd = Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0cab8f2e-a18f-41c9-b59b-521a72cb19df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+------+------+\n",
       "|   Sex|Pclass|\n",
       "+------+------+\n",
       "|  male|     3|\n",
       "|female|     1|\n",
       "+------+------+\n",
       "only showing top 2 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+------+------+\n|   Sex|Pclass|\n+------+------+\n|  male|     3|\n|female|     1|\n+------+------+\nonly showing top 2 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.select('Sex','Pclass').show(2)#to view selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0e79f540-9089-48cd-868e-4009dc0de311",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|    Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|PC 17599| 71.2833|        C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|  113803|    53.1|       C123|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|  113783|   26.55|       C103|       S|\n",
      "|         32|       1|     1|Spencer, Mrs. Wil...|female|null|    1|    0|PC 17569|146.5208|        B78|       C|\n",
      "|         53|       1|     1|Harper, Mrs. Henr...|female|49.0|    1|    0|PC 17572| 76.7292|        D33|       C|\n",
      "|         62|       1|     1| Icard, Miss. Amelie|female|38.0|    0|    0|  113572|    80.0|        B28|    null|\n",
      "|         89|       1|     1|Fortune, Miss. Ma...|female|23.0|    3|    2|   19950|   263.0|C23 C25 C27|       S|\n",
      "|        137|       1|     1|Newsom, Miss. Hel...|female|19.0|    0|    2|   11752| 26.2833|        D47|       S|\n",
      "|        152|       1|     1|Pears, Mrs. Thoma...|female|22.0|    1|    0|  113776|    66.6|         C2|       S|\n",
      "|        167|       1|     1|Chibnall, Mrs. (E...|female|null|    0|    1|  113505|    55.0|        E33|       S|\n",
      "|        178|       0|     1|Isham, Miss. Ann ...|female|50.0|    0|    0|PC 17595| 28.7125|        C49|       C|\n",
      "|        195|       1|     1|Brown, Mrs. James...|female|44.0|    0|    0|PC 17610| 27.7208|         B4|       C|\n",
      "|        196|       1|     1|Lurette, Miss. Elise|female|58.0|    0|    0|PC 17569|146.5208|        B80|       C|\n",
      "|        216|       1|     1|Newell, Miss. Mad...|female|31.0|    1|    0|   35273| 113.275|        D36|       C|\n",
      "|        219|       1|     1|Bazzani, Miss. Al...|female|32.0|    0|    0|   11813| 76.2917|        D15|       C|\n",
      "|        231|       1|     1|Harris, Mrs. Henr...|female|35.0|    1|    0|   36973|  83.475|        C83|       S|\n",
      "|        257|       1|     1|Thorne, Mrs. Gert...|female|null|    0|    0|PC 17585|    79.2|       null|       C|\n",
      "|        258|       1|     1|Cherry, Miss. Gladys|female|30.0|    0|    0|  110152|    86.5|        B77|       S|\n",
      "|        259|       1|     1|    Ward, Miss. Anna|female|35.0|    0|    0|PC 17755|512.3292|       null|       C|\n",
      "|        269|       1|     1|Graham, Mrs. Will...|female|58.0|    0|    1|PC 17582|153.4625|       C125|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.Pclass=='1') & (df.Sex=='female')).show()#Upper class Females\n",
    "\n",
    "#reference: https://sparkbyexamples.com/pyspark/pyspark-where-filter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5f2fb844-3743-4bc1-9221-3f671037d0da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((df.Pclass=='1') & (df.Sex=='female')).count()#total count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6582db5e-8231-489c-b39e-8a6029b2cb98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name| Sex| Age|SibSp|Parch|         Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|male|22.0|    1|    0|      A/5 21171|   7.25| null|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|male|35.0|    0|    0|         373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|male|null|    0|    0|         330877| 8.4583| null|       Q|\n",
      "|          8|       0|     3|Palsson, Master. ...|male| 2.0|    3|    1|         349909| 21.075| null|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|male|20.0|    0|    0|      A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|male|39.0|    1|    5|         347082| 31.275| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|male| 2.0|    4|    1|         382652| 29.125| null|       Q|\n",
      "|         27|       0|     3|Emir, Mr. Farred ...|male|null|    0|    0|           2631|  7.225| null|       C|\n",
      "|         30|       0|     3| Todoroff, Mr. Lalio|male|null|    0|    0|         349216| 7.8958| null|       S|\n",
      "|         37|       1|     3|    Mamee, Mr. Hanna|male|null|    0|    0|           2677| 7.2292| null|       C|\n",
      "|         38|       0|     3|Cann, Mr. Ernest ...|male|21.0|    0|    0|     A./5. 2152|   8.05| null|       S|\n",
      "|         43|       0|     3| Kraeff, Mr. Theodor|male|null|    0|    0|         349253| 7.8958| null|       C|\n",
      "|         46|       0|     3|Rogers, Mr. Willi...|male|null|    0|    0|S.C./A.4. 23567|   8.05| null|       S|\n",
      "|         47|       0|     3|   Lennon, Mr. Denis|male|null|    1|    0|         370371|   15.5| null|       Q|\n",
      "|         49|       0|     3| Samaan, Mr. Youssef|male|null|    2|    0|           2662|21.6792| null|       C|\n",
      "|         51|       0|     3|Panula, Master. J...|male| 7.0|    4|    1|        3101295|39.6875| null|       S|\n",
      "|         52|       0|     3|Nosworthy, Mr. Ri...|male|21.0|    0|    0|     A/4. 39886|    7.8| null|       S|\n",
      "|         58|       0|     3| Novel, Mr. Mansouer|male|28.5|    0|    0|           2697| 7.2292| null|       C|\n",
      "|         60|       0|     3|Goodwin, Master. ...|male|11.0|    5|    2|        CA 2144|   46.9| null|       S|\n",
      "|         61|       0|     3|Sirayanian, Mr. O...|male|22.0|    0|    0|           2669| 7.2292| null|       C|\n",
      "+-----------+--------+------+--------------------+----+----+-----+-----+---------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.Pclass=='3') & (df.Sex=='male')).show()#lower class males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e27b1159-35c4-4b18-a7c4-fb12f389a12d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((df.Pclass=='3') & (df.Sex=='male')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f5be9579-dbbc-4e3a-9718-e66df7fb3105",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ratio of Lower class - Males to Upper class Females : 3.6914893617021276\n"
     ]
    }
   ],
   "source": [
    "print('the ratio of Lower class - Males to Upper class Females :',df.filter((df.Pclass=='3') & (df.Sex=='male')).count()/df.filter((df.Pclass=='1') & (df.Sex=='female')).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(sex)|\n",
      "+----------+\n",
      "|       347|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(sex) from train where pclass=3 and sex='male'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(sex)|\n",
      "+----------+\n",
      "|        94|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(sex) from train where pclass=1 and sex='female'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------+\n",
      "|(CAST(scalarsubquery() AS DOUBLE) / CAST(scalarsubquery() AS DOUBLE))|\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                   3.6914893617021276|\n",
      "+---------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select (select count(sex) from train where pclass=3 and sex='male')/(select count(sex) from train where pclass=1 and sex='female')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d11b4d5b-0bea-4913-acd8-d0e0fb82be87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " #2.v Which was the costliest cabin of titanic? What was its fair?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4ad6dd04-f691-4b98-bff6-eb498dd16a7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---------+\n",
       "|max(Fare)|\n",
       "+---------+\n",
       "| 512.3292|\n",
       "+---------+\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+---------+\n|max(Fare)|\n+---------+\n| 512.3292|\n+---------+\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.agg({'Fare':'max'}).show()#maximum Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "57c6750e-b9e0-4c4d-86f5-66c8a53a7738",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------+\n",
       "|      Cabin|\n",
       "+-----------+\n",
       "|       null|\n",
       "|B51 B53 B55|\n",
       "|       B101|\n",
       "+-----------+\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+-----------+\n|      Cabin|\n+-----------+\n|       null|\n|B51 B53 B55|\n|       B101|\n+-----------+\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.filter(df.Fare == '512.3292').select('Cabin').show()#costliest cabins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|      cabin|max(Fare)|\n",
      "+-----------+---------+\n",
      "|B51 B53 B55| 512.3292|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select cabin, max(Fare) from train where cabin is not null group by cabin order by max(Fare) desc limit 1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f7be8dfd-c4f1-4f70-a356-1efd820195df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#3 . Using SparkML libraries execute the steps, as questioned below, in order to build a PySpark classification ML-model on Titanic dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4522be5c-1e0b-4a54-8240-0cf70a5a6236",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#3.i Find null values count of every feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e5e6c8f1-d310-40fa-931a-cbf8faef42d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2301b224-4b9a-437f-bb8e-e786092f2885",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reference :https://stackoverflow.com/questions/44627386/how-to-find-count-of-null-and-nan-values-for-each-column-in-a-pyspark-dataframe\n",
    "df.select([count(when(isnan(c) | col(c).isNull(),c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "90e640ee-a135-4ebb-81e7-9159ec62bc64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Age colum has 177 null values\n",
    "#Cabin colum has 687 null values\n",
    "#Embarked colum has  2 null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7cc9dee-548c-40c8-9bc5-526ed48e74aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#3.ii For missing string feature add a new value as ‘missing’. For missing numeric values replace by the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4da17f62-4ee2-4b9b-b8bd-5973ec2c44a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#we have no missing string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cfeb88ec-78a7-4e2e-8e62-b9c0c41b410c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Cabin      |count|\n",
      "+-----------+-----+\n",
      "|null       |687  |\n",
      "|B96 B98    |4    |\n",
      "|C23 C25 C27|4    |\n",
      "|G6         |4    |\n",
      "|D          |3    |\n",
      "|F2         |3    |\n",
      "|C22 C26    |3    |\n",
      "|E101       |3    |\n",
      "|F33        |3    |\n",
      "|E33        |2    |\n",
      "|B51 B53 B55|2    |\n",
      "|B18        |2    |\n",
      "|D20        |2    |\n",
      "|C83        |2    |\n",
      "|D35        |2    |\n",
      "|C78        |2    |\n",
      "|B20        |2    |\n",
      "|E44        |2    |\n",
      "|E8         |2    |\n",
      "|B22        |2    |\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Cabin').count().orderBy('count', ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9e8cb158-9051-4a44-946e-0a79bb927cb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|  Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-------+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|missing|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|    C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|missing|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|   C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|missing|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583|missing|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|    E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|missing|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|missing|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|missing|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|     G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|   C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|missing|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|missing|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|missing|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|missing|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|missing|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0|missing|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|missing|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225|missing|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df.na.fill({'Cabin':'missing'})#as cabin is string column\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "470d7f9d-af0a-47f2-a18f-c45ae05342d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|S       |644  |\n",
      "|C       |168  |\n",
      "|Q       |77   |\n",
      "|null    |2    |\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Embarked').count().orderBy('count', ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "68882c45-7d05-4f78-8290-0a8bc7699043",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+-------------------------------------------------------+------+----+-----+-----+----------------+-------+-------+--------+\n",
      "|PassengerId|Survived|Pclass|Name                                                   |Sex   |Age |SibSp|Parch|Ticket          |Fare   |Cabin  |Embarked|\n",
      "+-----------+--------+------+-------------------------------------------------------+------+----+-----+-----+----------------+-------+-------+--------+\n",
      "|1          |0       |3     |Braund, Mr. Owen Harris                                |male  |22.0|1    |0    |A/5 21171       |7.25   |missing|S       |\n",
      "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)    |female|38.0|1    |0    |PC 17599        |71.2833|C85    |C       |\n",
      "|3          |1       |3     |Heikkinen, Miss. Laina                                 |female|26.0|0    |0    |STON/O2. 3101282|7.925  |missing|S       |\n",
      "|4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)           |female|35.0|1    |0    |113803          |53.1   |C123   |S       |\n",
      "|5          |0       |3     |Allen, Mr. William Henry                               |male  |35.0|0    |0    |373450          |8.05   |missing|S       |\n",
      "|6          |0       |3     |Moran, Mr. James                                       |male  |null|0    |0    |330877          |8.4583 |missing|Q       |\n",
      "|7          |0       |1     |McCarthy, Mr. Timothy J                                |male  |54.0|0    |0    |17463           |51.8625|E46    |S       |\n",
      "|8          |0       |3     |Palsson, Master. Gosta Leonard                         |male  |2.0 |3    |1    |349909          |21.075 |missing|S       |\n",
      "|9          |1       |3     |Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      |female|27.0|0    |2    |347742          |11.1333|missing|S       |\n",
      "|10         |1       |2     |Nasser, Mrs. Nicholas (Adele Achem)                    |female|14.0|1    |0    |237736          |30.0708|missing|C       |\n",
      "|11         |1       |3     |Sandstrom, Miss. Marguerite Rut                        |female|4.0 |1    |1    |PP 9549         |16.7   |G6     |S       |\n",
      "|12         |1       |1     |Bonnell, Miss. Elizabeth                               |female|58.0|0    |0    |113783          |26.55  |C103   |S       |\n",
      "|13         |0       |3     |Saundercock, Mr. William Henry                         |male  |20.0|0    |0    |A/5. 2151       |8.05   |missing|S       |\n",
      "|14         |0       |3     |Andersson, Mr. Anders Johan                            |male  |39.0|1    |5    |347082          |31.275 |missing|S       |\n",
      "|15         |0       |3     |Vestrom, Miss. Hulda Amanda Adolfina                   |female|14.0|0    |0    |350406          |7.8542 |missing|S       |\n",
      "|16         |1       |2     |Hewlett, Mrs. (Mary D Kingcome)                        |female|55.0|0    |0    |248706          |16.0   |missing|S       |\n",
      "|17         |0       |3     |Rice, Master. Eugene                                   |male  |2.0 |4    |1    |382652          |29.125 |missing|Q       |\n",
      "|18         |1       |2     |Williams, Mr. Charles Eugene                           |male  |null|0    |0    |244373          |13.0   |missing|S       |\n",
      "|19         |0       |3     |Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)|female|31.0|1    |0    |345763          |18.0   |missing|S       |\n",
      "|20         |1       |3     |Masselmani, Mrs. Fatima                                |female|null|0    |0    |2649            |7.225  |missing|C       |\n",
      "+-----------+--------+------+-------------------------------------------------------+------+----+-----+-----+----------------+-------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df.na.fill({'Embarked':'missing'})#as Embarked is string column\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "36f423d3-90b4-44ba-bd1f-d953be2aa4dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| Age|count|\n",
      "+----+-----+\n",
      "|null|  177|\n",
      "|24.0|   30|\n",
      "+----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reference:https://stackoverflow.com/questions/51063624/whats-the-equivalent-of-pandas-value-counts-in-pyspark\n",
    "#for numeric vlaues replace by mode\n",
    "\n",
    "df.groupby('Age').count().orderBy('count', ascending=False).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ecce50dd-3fb4-4d70-8471-33299c8de2db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|  Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-------+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|missing|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|    C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|missing|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|   C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|missing|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|24.0|    0|    0|          330877| 8.4583|missing|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|    E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|missing|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|missing|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|missing|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|     G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|   C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|missing|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|missing|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|missing|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|missing|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|missing|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|24.0|    0|    0|          244373|   13.0|missing|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|missing|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|24.0|    0|    0|            2649|  7.225|missing|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reference:https://sparkbyexamples.com/pyspark/pyspark-fillna-fill-replace-null-values/#:~:text=PySpark%20fillna()%20%26%20fill()%20%E2%80%93%20Replace%20NULL%2FNone%20Values&text=In%20PySpark%2C%20DataFrame.,or%20any%20constant%20literal%20values.\n",
    "\n",
    "#replace value by 24\n",
    "\n",
    "df=df.na.fill({'Age':24.0})#as age is numeric column\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e2ab7f19-5528-4ebd-9f6f-6de3df37e833",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| Age|count|\n",
      "+----+-----+\n",
      "|24.0|  207|\n",
      "|22.0|   27|\n",
      "+----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Age').count().orderBy('count', ascending=False).show(2)#checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cf5ccbee-749a-40db-a5b4-15b3ff7d76b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##3.iii Convert all string columns into numeric values using StringIndexer transformer and make sure now DataFrame does not have any string columns anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "831ad54c-c68e-485e-bea7-dcfa1d5ac790",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = false)\n",
      " |-- Embarked: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "97a492da-c520-4554-b6bb-6566cdf9268f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Ticket|   Fare|  Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-------+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|A/5 21171|   7.25|missing|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0| PC 17599|71.2833|    C85|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "597ba71b-e529-478e-9b4f-ec985c3db808",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#PassengerID, Name, Ticket, Cabin can be droped\n",
    "df=df.drop('PassengerID', 'Name', 'Ticket', 'Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a3b0b4dc-4824-482f-9e27-7f824a21d695",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|       S|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|       C|\n",
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e68a2855-6120-42c9-bfa1-efd6886aba74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fd815999-b45b-4c4b-a7b7-7009d91dd8a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "indexers=[StringIndexer(inputCol=c,outputCol=c+'_index').fit(df)  for c in ['Sex','Embarked']]\n",
    "pipeline=Pipeline(stages=indexers)\n",
    "df=pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "733c3b6b-2c19-4cd8-b343-455629ab0b1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+---------+--------------+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Sex_index|Embarked_index|\n",
      "+--------+------+------+----+-----+-----+-------+--------+---------+--------------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|       S|      0.0|           0.0|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|       C|      1.0|           1.0|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|       S|      1.0|           0.0|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|       S|      1.0|           0.0|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|       S|      0.0|           0.0|\n",
      "|       0|     3|  male|24.0|    0|    0| 8.4583|       Q|      0.0|           2.0|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|       S|      0.0|           0.0|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|      0.0|           0.0|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|       S|      1.0|           0.0|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|       C|      1.0|           1.0|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|       S|      1.0|           0.0|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|       S|      1.0|           0.0|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|       S|      0.0|           0.0|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|       S|      0.0|           0.0|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|       S|      1.0|           0.0|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|       S|      1.0|           0.0|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|      0.0|           2.0|\n",
      "|       1|     2|  male|24.0|    0|    0|   13.0|       S|      0.0|           0.0|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|       S|      1.0|           0.0|\n",
      "|       1|     3|female|24.0|    0|    0|  7.225|       C|      1.0|           1.0|\n",
      "+--------+------+------+----+-----+-----+-------+--------+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6324601e-59d0-45a7-9ecf-5d6e6ccb3abb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=df.drop('Sex','Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "742d5dc7-a579-422b-ba57-1d2bbd1777ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+---------+--------------+\n",
      "|Survived|Pclass| Age|SibSp|Parch|   Fare|Sex_index|Embarked_index|\n",
      "+--------+------+----+-----+-----+-------+---------+--------------+\n",
      "|       0|     3|22.0|    1|    0|   7.25|      0.0|           0.0|\n",
      "|       1|     1|38.0|    1|    0|71.2833|      1.0|           1.0|\n",
      "|       1|     3|26.0|    0|    0|  7.925|      1.0|           0.0|\n",
      "|       1|     1|35.0|    1|    0|   53.1|      1.0|           0.0|\n",
      "|       0|     3|35.0|    0|    0|   8.05|      0.0|           0.0|\n",
      "|       0|     3|24.0|    0|    0| 8.4583|      0.0|           2.0|\n",
      "|       0|     1|54.0|    0|    0|51.8625|      0.0|           0.0|\n",
      "|       0|     3| 2.0|    3|    1| 21.075|      0.0|           0.0|\n",
      "|       1|     3|27.0|    0|    2|11.1333|      1.0|           0.0|\n",
      "|       1|     2|14.0|    1|    0|30.0708|      1.0|           1.0|\n",
      "|       1|     3| 4.0|    1|    1|   16.7|      1.0|           0.0|\n",
      "|       1|     1|58.0|    0|    0|  26.55|      1.0|           0.0|\n",
      "|       0|     3|20.0|    0|    0|   8.05|      0.0|           0.0|\n",
      "|       0|     3|39.0|    1|    5| 31.275|      0.0|           0.0|\n",
      "|       0|     3|14.0|    0|    0| 7.8542|      1.0|           0.0|\n",
      "|       1|     2|55.0|    0|    0|   16.0|      1.0|           0.0|\n",
      "|       0|     3| 2.0|    4|    1| 29.125|      0.0|           2.0|\n",
      "|       1|     2|24.0|    0|    0|   13.0|      0.0|           0.0|\n",
      "|       0|     3|31.0|    1|    0|   18.0|      1.0|           0.0|\n",
      "|       1|     3|24.0|    0|    0|  7.225|      1.0|           1.0|\n",
      "+--------+------+----+-----+-----+-------+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6f3993b3-5f81-4a91-b22c-006a706bab0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "###3.iv Using vectorAssembler combines all columns (except target column i.e., 'Survived’) of spark DataFrame into single column (name as features).   DataFrame should now contains only two columns features and Survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b90923bb-7013-45d4-9b32-885173995dc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d4b3839d-ef7c-41a1-9030-cb87657dffa7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature = VectorAssembler(inputCols=df.columns[1:],outputCol=\"features\")\n",
    "feature_vector= feature.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0eeee972-fa26-4157-9254-1b2f0d72dc2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+---------+--------------+--------------------+\n",
      "|Survived|Pclass| Age|SibSp|Parch|   Fare|Sex_index|Embarked_index|            features|\n",
      "+--------+------+----+-----+-----+-------+---------+--------------+--------------------+\n",
      "|       0|     3|22.0|    1|    0|   7.25|      0.0|           0.0|[3.0,22.0,1.0,0.0...|\n",
      "|       1|     1|38.0|    1|    0|71.2833|      1.0|           1.0|[1.0,38.0,1.0,0.0...|\n",
      "|       1|     3|26.0|    0|    0|  7.925|      1.0|           0.0|[3.0,26.0,0.0,0.0...|\n",
      "|       1|     1|35.0|    1|    0|   53.1|      1.0|           0.0|[1.0,35.0,1.0,0.0...|\n",
      "|       0|     3|35.0|    0|    0|   8.05|      0.0|           0.0|(7,[0,1,4],[3.0,3...|\n",
      "|       0|     3|24.0|    0|    0| 8.4583|      0.0|           2.0|[3.0,24.0,0.0,0.0...|\n",
      "|       0|     1|54.0|    0|    0|51.8625|      0.0|           0.0|(7,[0,1,4],[1.0,5...|\n",
      "|       0|     3| 2.0|    3|    1| 21.075|      0.0|           0.0|[3.0,2.0,3.0,1.0,...|\n",
      "|       1|     3|27.0|    0|    2|11.1333|      1.0|           0.0|[3.0,27.0,0.0,2.0...|\n",
      "|       1|     2|14.0|    1|    0|30.0708|      1.0|           1.0|[2.0,14.0,1.0,0.0...|\n",
      "|       1|     3| 4.0|    1|    1|   16.7|      1.0|           0.0|[3.0,4.0,1.0,1.0,...|\n",
      "|       1|     1|58.0|    0|    0|  26.55|      1.0|           0.0|[1.0,58.0,0.0,0.0...|\n",
      "|       0|     3|20.0|    0|    0|   8.05|      0.0|           0.0|(7,[0,1,4],[3.0,2...|\n",
      "|       0|     3|39.0|    1|    5| 31.275|      0.0|           0.0|[3.0,39.0,1.0,5.0...|\n",
      "|       0|     3|14.0|    0|    0| 7.8542|      1.0|           0.0|[3.0,14.0,0.0,0.0...|\n",
      "|       1|     2|55.0|    0|    0|   16.0|      1.0|           0.0|[2.0,55.0,0.0,0.0...|\n",
      "|       0|     3| 2.0|    4|    1| 29.125|      0.0|           2.0|[3.0,2.0,4.0,1.0,...|\n",
      "|       1|     2|24.0|    0|    0|   13.0|      0.0|           0.0|(7,[0,1,4],[2.0,2...|\n",
      "|       0|     3|31.0|    1|    0|   18.0|      1.0|           0.0|[3.0,31.0,1.0,0.0...|\n",
      "|       1|     3|24.0|    0|    0|  7.225|      1.0|           1.0|[3.0,24.0,0.0,0.0...|\n",
      "+--------+------+----+-----+-----+-------+---------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_vector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1f20ce80-6f8c-403f-990d-d12e93fa8086",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "###3.v Split the vectorized DataFrame into training and test sets with one third records being held for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dcddd101-1097-4cf7-9dc0-53c107e09b0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = feature_vector.randomSplit([0.8, 0.2],seed = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3c2142f1-b083-4a41-9572-c455840d0da0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+--------+---------+--------------+--------------------+\n",
      "|Survived|Pclass| Age|SibSp|Parch|    Fare|Sex_index|Embarked_index|            features|\n",
      "+--------+------+----+-----+-----+--------+---------+--------------+--------------------+\n",
      "|       0|     1| 2.0|    1|    2|  151.55|      1.0|           0.0|[1.0,2.0,1.0,2.0,...|\n",
      "|       0|     1|18.0|    1|    0|   108.9|      0.0|           1.0|[1.0,18.0,1.0,0.0...|\n",
      "|       0|     1|19.0|    1|    0|    53.1|      0.0|           0.0|[1.0,19.0,1.0,0.0...|\n",
      "|       0|     1|19.0|    3|    2|   263.0|      0.0|           0.0|[1.0,19.0,3.0,2.0...|\n",
      "|       0|     1|21.0|    0|    1| 77.2875|      0.0|           0.0|[1.0,21.0,0.0,1.0...|\n",
      "|       0|     1|24.0|    0|    0|     0.0|      0.0|           0.0|(7,[0,1],[1.0,24.0])|\n",
      "|       0|     1|24.0|    0|    0|  25.925|      0.0|           0.0|(7,[0,1,4],[1.0,2...|\n",
      "|       0|     1|24.0|    0|    0|    26.0|      0.0|           0.0|(7,[0,1,4],[1.0,2...|\n",
      "|       0|     1|24.0|    0|    0|   26.55|      0.0|           0.0|(7,[0,1,4],[1.0,2...|\n",
      "|       0|     1|24.0|    0|    0| 27.7208|      0.0|           1.0|[1.0,24.0,0.0,0.0...|\n",
      "|       0|     1|24.0|    0|    0|    35.0|      0.0|           0.0|(7,[0,1,4],[1.0,2...|\n",
      "|       0|     1|24.0|    0|    0|    50.0|      0.0|           0.0|(7,[0,1,4],[1.0,2...|\n",
      "|       0|     1|24.0|    0|    0|    52.0|      0.0|           0.0|(7,[0,1,4],[1.0,2...|\n",
      "|       0|     1|24.0|    0|    0|    79.2|      0.0|           1.0|[1.0,24.0,0.0,0.0...|\n",
      "|       0|     1|24.0|    0|    0| 227.525|      0.0|           1.0|[1.0,24.0,0.0,0.0...|\n",
      "|       0|     1|24.0|    0|    1|247.5208|      0.0|           1.0|[1.0,24.0,0.0,1.0...|\n",
      "|       0|     1|25.0|    1|    2|  151.55|      1.0|           0.0|[1.0,25.0,1.0,2.0...|\n",
      "|       0|     1|27.0|    0|    2|   211.5|      0.0|           1.0|[1.0,27.0,0.0,2.0...|\n",
      "|       0|     1|28.0|    0|    0|    47.1|      0.0|           0.0|(7,[0,1,4],[1.0,2...|\n",
      "|       0|     1|29.0|    0|    0|    30.0|      0.0|           0.0|(7,[0,1,4],[1.0,2...|\n",
      "+--------+------+----+-----+-----+--------+---------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8897fb8d-db8e-4d5e-a43e-a4a9faf34bb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "####3.vi Train default LogisticRegression model with features as 'featuresCol'   and ‘Survived’ as label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "622f3909-359c-47e3-8bbe-8f96d8348976",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "854e61ef-ccdd-463f-ab31-df27b38cbee7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       0|[1.0,22.0,0.0,0.0...|\n",
      "|       1.0|       0|(7,[0,1],[1.0,24.0])|\n",
      "|       1.0|       0|[1.0,24.0,0.0,0.0...|\n",
      "|       1.0|       0|[1.0,24.0,0.0,0.0...|\n",
      "|       1.0|       0|(7,[0,1,4],[1.0,2...|\n",
      "|       1.0|       0|[1.0,24.0,0.0,0.0...|\n",
      "|       1.0|       0|(7,[0,1,4],[1.0,2...|\n",
      "|       1.0|       0|(7,[0,1,4],[1.0,2...|\n",
      "|       1.0|       0|[1.0,28.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,29.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,31.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,37.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,38.0,0.0,1.0...|\n",
      "|       0.0|       0|[1.0,45.0,1.0,0.0...|\n",
      "|       0.0|       0|(7,[0,1,4],[1.0,4...|\n",
      "|       0.0|       0|[1.0,58.0,0.0,2.0...|\n",
      "|       0.0|       0|(7,[0,1,4],[1.0,6...|\n",
      "|       0.0|       0|(7,[0,1,4],[1.0,6...|\n",
      "|       0.0|       0|[1.0,71.0,0.0,0.0...|\n",
      "|       0.0|       0|[2.0,19.0,1.0,1.0...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "#Training algo\n",
    "lrModel = lr.fit(trainingData)\n",
    "lr_prediction = lrModel.transform(testData)\n",
    "lr_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e2cbd918-e6b9-4803-8cae-226a6e119c54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression is = 0.787234\n",
      "Test Error of LogisticRegression = 0.212766 \n"
     ]
    }
   ],
   "source": [
    "lr_accuracy = evaluator.evaluate(lr_prediction)\n",
    "print(\"Accuracy of LogisticRegression is = %g\"% (lr_accuracy))\n",
    "print(\"Test Error of LogisticRegression = %g \" % (1.0 - lr_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c2b437b6-9059-4c68-86a9-d15acd6313c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#3.vii Find F1-score of trained models on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "48449fce-1c56-460d-ad40-0a6463f20f86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Titanic_Dataset_using_Pyspark",
   "notebookOrigID": 712203315681609,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
